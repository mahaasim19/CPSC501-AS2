{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CHDModel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wkw87MplLSTb",
        "colab_type": "code",
        "outputId": "fd05a035-9ca9-451b-ac32-6be828b54231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import functools\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "#TRAIN_DATA_URL = \"heart_train.csv\"\n",
        "#TEST_DATA_URL = \"heart_test.csv\"\n",
        "\n",
        "\n",
        "\n",
        "#train_file_path = tf.keras.utils.get_file(\"heart_train.csv\",TRAIN_DATA_URL)\n",
        "#test_file_path = tf.keras.utils.get_file(\"heart_test.csv\",TEST_DATA_URL)\n",
        "\n",
        "\n",
        "\n",
        "# Make numpy values easier to read.\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "\n",
        "\n",
        "\n",
        "#!head {'heart_train.csv'}\n",
        "\n",
        "\n",
        "\n",
        "LABEL_COLUMN = 'chd'\n",
        "LABELS = [0, -1]\n",
        "\n",
        "\n",
        "\n",
        "def get_dataset(file_path, **kwargs):\n",
        "  dataset = tf.data.experimental.make_csv_dataset(\n",
        "      file_path,\n",
        "      batch_size=32, # Artificially small to make examples easier to show.\n",
        "      label_name=LABEL_COLUMN,\n",
        "      na_value=\"?\",\n",
        "      num_epochs=1,\n",
        "      ignore_errors=True, \n",
        "      **kwargs)\n",
        "  return dataset\n",
        "\n",
        "\n",
        "\n",
        "raw_train_data = get_dataset(\"heart_train.csv\")\n",
        "raw_test_data = get_dataset(\"heart_test.csv\")\n",
        "\n",
        "\n",
        "#def show_batch(dataset):\n",
        "#  for batch, label in dataset.take(1):\n",
        "#    for key, value in batch.items():\n",
        "#    print(\"{:20s}: {}\".format(key,value.numpy()))\n",
        "\n",
        "\n",
        "#show_batch(raw_train_data)\n",
        "\n",
        "\n",
        "\n",
        "CSV_COLUMNS = ['row.names', 'sbp', 'tobacco', 'ldl', 'adiposity', 'famhist', 'typea', 'obesity', 'alcohol', 'age','chd']\n",
        "\n",
        "temp_dataset = get_dataset(\"heart_train.csv\", column_names=CSV_COLUMNS)\n",
        "\n",
        "show_batch(temp_dataset)\n",
        "\n",
        "\n",
        "\n",
        "SELECT_COLUMNS = ['sbp', 'tobacco', 'ldl', 'adiposity', 'famhist', 'typea', 'obesity', 'alcohol', 'age','chd']\n",
        "\n",
        "temp_dataset = get_dataset(\"heart_train.csv\", select_columns=SELECT_COLUMNS)\n",
        "\n",
        "show_batch(temp_dataset)\n",
        "\n",
        "\n",
        "\n",
        "#def pack(features, label):\n",
        "#  return tf.stack(list(features.values()), axis=-1), label\n",
        "\n",
        "\n",
        "#packed_dataset = temp_dataset.map(pack)\n",
        "\n",
        "#for features, labels in packed_dataset.take(1):\n",
        "#  print(features.numpy())\n",
        "#  print()\n",
        "#  print(labels.numpy())\n",
        "\n",
        "\n",
        "\n",
        "#show_batch(raw_train_data)\n",
        "\n",
        "example_batch, labels_batch = next(iter(temp_dataset)) \n",
        "\n",
        "\n",
        "class PackNumericFeatures(object):\n",
        "  def __init__(self, names):\n",
        "    self.names = names\n",
        "\n",
        "  def __call__(self, features, labels):\n",
        "    numeric_features = [features.pop(name) for name in self.names]\n",
        "    numeric_features = [tf.cast(feat, tf.float32) for feat in numeric_features]\n",
        "    numeric_features = tf.stack(numeric_features, axis=-1)\n",
        "    features['numeric'] = numeric_features\n",
        "\n",
        "    return features, labels\n",
        "\n",
        "\n",
        "NUMERIC_FEATURES = ['sbp', 'tobacco', 'ldl', 'adiposity', 'typea', 'obesity', 'alcohol', 'age']\n",
        "\n",
        "packed_train_data = raw_train_data.map(\n",
        "    PackNumericFeatures(NUMERIC_FEATURES))\n",
        "\n",
        "packed_test_data = raw_test_data.map(\n",
        "    PackNumericFeatures(NUMERIC_FEATURES))\n",
        "\n",
        "#show_batch(\"heart_train.csv\")\n",
        "\n",
        "example_batch, labels_batch = next(iter(packed_train_data)) \n",
        "\n",
        "import pandas as pd\n",
        "desc = pd.read_csv(\"heart_train.csv\")[NUMERIC_FEATURES].describe()\n",
        "desc\n",
        "\n",
        "\n",
        "MEAN = np.array(desc.T['mean'])\n",
        "STD = np.array(desc.T['std'])\n",
        "\n",
        "\n",
        "def normalize_numeric_data(data, mean, std):\n",
        "  # Center the data\n",
        "  return (data-mean)/std\n",
        "\n",
        "\n",
        "# See what you just created.\n",
        "normalizer = functools.partial(normalize_numeric_data, mean=MEAN, std=STD)\n",
        "\n",
        "numeric_column = tf.feature_column.numeric_column('numeric', normalizer_fn=normalizer, shape=[len(NUMERIC_FEATURES)])\n",
        "numeric_columns = [numeric_column]\n",
        "numeric_column\n",
        "\n",
        "\n",
        "example_batch['numeric']\n",
        "\n",
        "numeric_layer = tf.keras.layers.DenseFeatures(numeric_columns)\n",
        "numeric_layer(example_batch).numpy()\n",
        "\n",
        "\n",
        "CATEGORIES = {\n",
        "    'famhist' : ['Present', 'Absent']\n",
        "}\n",
        "\n",
        "categorical_columns = []\n",
        "for feature, vocab in CATEGORIES.items():\n",
        "  cat_col = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "        key=feature, vocabulary_list=vocab)\n",
        "  categorical_columns.append(tf.feature_column.indicator_column(cat_col))\n",
        "\n",
        "\n",
        "# See what you just created.\n",
        "categorical_columns\n",
        "\n",
        "categorical_layer = tf.keras.layers.DenseFeatures(categorical_columns)\n",
        "print(categorical_layer(example_batch).numpy()[0])\n",
        "\n",
        "\n",
        "preprocessing_layer = tf.keras.layers.DenseFeatures(categorical_columns+numeric_columns)\n",
        "\n",
        "print(preprocessing_layer(example_batch).numpy()[0])\n",
        "\n",
        "#Build the model\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  preprocessing_layer,\n",
        "  tf.keras.layers.Dense(1000, activation='elu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Dense(1000, activation='elu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Dense(1000, activation='elu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  #tf.keras.layers.Dense(256, activation='elu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "  #tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(0.001)),\n",
        "\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "#Train, evaluate, and predict\n",
        "\n",
        "train_data = packed_train_data.shuffle(500)\n",
        "\n",
        "#train_data = packed_train_data\n",
        "test_data = packed_test_data\n",
        "\n",
        "\n",
        "model.fit(train_data, epochs=30)\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "\n",
        "print('\\n\\nTest Loss {}, Test Accuracy {}'.format(test_loss, test_accuracy))\n",
        "\n",
        "\n",
        "\n",
        "predictions = model.predict(test_data)\n",
        "\n",
        "# Show some results\n",
        "for prediction, survived in zip(predictions[:10], list(test_data)[0][1][:10]):\n",
        "  print(\"Predicted survival: {:.2%}\".format(prediction[0]),\n",
        "        \" | Actual outcome: \",\n",
        "        (\"1\" if bool(survived) else \"0\"))\n",
        "\n",
        "\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "row.names           : [453 436 406 407 413 419 427 417 461 410 421 412 437 450 456 443 438 444\n",
            " 401 448 460 420 411 428 409 416 447 458 446 452 442 397]\n",
            "sbp                 : [120 132 160 116 166 176 132 134 108 112 126 178 136 124 146 120 138 166\n",
            " 126 142 182 132 120 142 200 146 136 170 142 136 110 142]\n",
            "tobacco             : [ 0.    0.    1.15  2.38  0.8   0.    0.    1.1   3.    4.2   0.   20.\n",
            "  0.    1.8   0.64  0.    0.    6.    0.    0.    4.2   2.8   0.    1.32\n",
            " 19.2   6.4   2.8   0.4   3.    1.81  0.    0.  ]\n",
            "ldl                 : [ 2.77  3.55 10.19  5.67  5.63  3.14  3.3   3.54  1.59  3.58  4.55  9.78\n",
            "  1.77  3.74  4.82  3.98  1.86  8.8   3.57  4.32  4.41  4.79  3.1   7.63\n",
            "  4.43  5.62  2.53  4.11  3.69  3.31  7.14  3.54]\n",
            "adiposity           : [13.35  8.66 39.71 29.01 36.21 31.04 21.61 20.41 15.23 27.14 29.18 33.55\n",
            " 20.37 16.64 28.02 13.19 18.35 37.89 26.01 25.22 32.1  20.47 26.97 29.98\n",
            " 40.6  33.05  9.28 42.06 25.1   6.74 28.28 16.64]\n",
            "famhist             : [b'Absent' b'Present' b'Absent' b'Present' b'Absent' b'Present' b'Absent'\n",
            " b'Present' b'Absent' b'Absent' b'Absent' b'Absent' b'Absent' b'Present'\n",
            " b'Absent' b'Present' b'Present' b'Absent' b'Absent' b'Absent' b'Absent'\n",
            " b'Present' b'Absent' b'Present' b'Present' b'Present' b'Present'\n",
            " b'Present' b'Absent' b'Absent' b'Absent' b'Absent']\n",
            "typea               : [67 61 31 54 50 45 42 58 40 52 48 37 45 42 60 47 59 39 61 47 52 50 41 57\n",
            " 55 57 61 56 60 63 57 58]\n",
            "obesity             : [23.37 18.5  31.65 27.26 34.72 30.18 24.92 24.54 20.09 26.83 24.94 27.29\n",
            " 21.51 22.26 28.11 21.89 25.38 28.7  26.3  28.92 28.61 22.15 24.8  31.16\n",
            " 32.04 31.03 20.7  33.1  30.08 19.57 29.   25.97]\n",
            "alcohol             : [ 1.03  3.87 20.52 15.77 28.8   4.63 32.61 39.91 26.64  2.06 36.    2.88\n",
            "  2.06 10.49  8.23  0.    6.51 43.2   7.97  6.53 18.72 11.73  0.   72.93\n",
            " 36.    0.74  4.55  2.06 38.88 24.94  0.    8.36]\n",
            "age                 : [18 16 57 51 60 45 33 39 55 40 41 62 16 20 39 16 17 52 47 34 52 48 16 33\n",
            " 60 46 25 57 27 24 32 27]\n",
            "sbp                 : [142 126 132 132 150 162 164 120 124 110 134 112 136 120 134 120 136 132\n",
            " 134 130 178 120 160 142 120 208 124 142 146 176 142 116]\n",
            "tobacco             : [ 0.    0.    2.8   0.   13.8   7.    8.2   0.    1.6   0.    0.57  4.2\n",
            "  2.8   0.    1.1   0.    0.    7.2   6.1   4.   20.    0.    1.15  1.32\n",
            "  0.    5.04  1.8   0.    0.64  6.    3.    2.38]\n",
            "ldl                 : [ 3.54  3.57  4.79  4.82  5.1   7.67 14.16  3.98  7.22  7.14  4.75  3.58\n",
            "  2.53  2.77  3.54  2.46  4.    3.65  4.77  2.4   9.78  3.57 10.19  7.63\n",
            "  3.1   5.19  3.74  4.32  4.82  3.98  3.69  5.67]\n",
            "adiposity           : [16.64 26.01 20.47 33.41 29.45 34.34 36.85 13.19 39.68 28.28 23.07 27.14\n",
            "  9.28 13.35 20.41 13.39 19.06 17.16 26.08 17.42 33.55 23.22 39.71 29.98\n",
            " 26.97 20.71 16.64 25.22 28.02 17.2  25.1  29.01]\n",
            "famhist             : [b'Absent' b'Absent' b'Present' b'Present' b'Present' b'Present' b'Absent'\n",
            " b'Present' b'Present' b'Absent' b'Absent' b'Absent' b'Present' b'Absent'\n",
            " b'Present' b'Absent' b'Absent' b'Present' b'Absent' b'Absent' b'Absent'\n",
            " b'Absent' b'Absent' b'Present' b'Absent' b'Present' b'Present' b'Absent'\n",
            " b'Absent' b'Present' b'Absent' b'Present']\n",
            "typea               : [58 61 50 62 52 33 52 47 36 57 67 52 61 67 58 47 40 56 47 60 37 58 31 57\n",
            " 41 52 42 47 60 52 60 54]\n",
            "obesity             : [25.97 26.3  22.15 14.7  27.92 30.77 28.5  21.89 31.5  29.   26.33 26.83\n",
            " 20.7  23.37 24.54 22.01 21.94 23.25 23.82 22.05 27.29 27.2  31.65 31.16\n",
            " 24.8  25.12 22.26 28.92 28.11 21.07 30.08 27.26]\n",
            "alcohol             : [ 8.36  7.97 11.73  0.   77.76  0.   17.02  0.    0.    0.    0.    2.06\n",
            "  4.55  1.03 39.91  0.51  2.06  0.    1.03  0.    2.88  0.   20.52 72.93\n",
            "  0.   24.27 10.49  6.53  8.23  4.11 38.88 15.77]\n",
            "age                 : [27 47 48 46 55 62 55 16 51 32 37 40 25 18 39 18 16 34 49 40 62 32 57 33\n",
            " 16 58 20 34 39 61 27 51]\n",
            "[0. 1.]\n",
            "[ 0.     1.    -0.33  -0.333 -0.52  -2.19   1.328 -1.446  0.262 -1.063]\n",
            "Epoch 1/30\n",
            "3/3 [==============================] - 1s 311ms/step - loss: 2.7968 - accuracy: 0.5970\n",
            "Epoch 2/30\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 2.5750 - accuracy: 0.7313\n",
            "Epoch 3/30\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 2.6263 - accuracy: 0.7015\n",
            "Epoch 4/30\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 2.4454 - accuracy: 0.8209\n",
            "Epoch 5/30\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 2.6128 - accuracy: 0.7612\n",
            "Epoch 6/30\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 2.4383 - accuracy: 0.7910\n",
            "Epoch 7/30\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 2.4339 - accuracy: 0.8060\n",
            "Epoch 8/30\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 2.4252 - accuracy: 0.8060\n",
            "Epoch 9/30\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 2.4504 - accuracy: 0.7313\n",
            "Epoch 10/30\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 2.4310 - accuracy: 0.6866\n",
            "Epoch 11/30\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 2.3467 - accuracy: 0.8060\n",
            "Epoch 12/30\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 2.3918 - accuracy: 0.8209\n",
            "Epoch 13/30\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 2.2284 - accuracy: 0.8060\n",
            "Epoch 14/30\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 2.2762 - accuracy: 0.8060\n",
            "Epoch 15/30\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 2.3249 - accuracy: 0.7612\n",
            "Epoch 16/30\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 2.5406 - accuracy: 0.7313\n",
            "Epoch 17/30\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 2.3768 - accuracy: 0.7164\n",
            "Epoch 18/30\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 2.7277 - accuracy: 0.7015\n",
            "Epoch 19/30\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 2.4234 - accuracy: 0.7164\n",
            "Epoch 20/30\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 2.3760 - accuracy: 0.7612\n",
            "Epoch 21/30\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 2.6710 - accuracy: 0.8209\n",
            "Epoch 22/30\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 2.4563 - accuracy: 0.7612\n",
            "Epoch 23/30\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 2.7231 - accuracy: 0.7761\n",
            "Epoch 24/30\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 2.6020 - accuracy: 0.6866\n",
            "Epoch 25/30\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 2.4468 - accuracy: 0.6716\n",
            "Epoch 26/30\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 2.3690 - accuracy: 0.7463\n",
            "Epoch 27/30\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 2.5646 - accuracy: 0.7164\n",
            "Epoch 28/30\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 2.1133 - accuracy: 0.8060\n",
            "Epoch 29/30\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 2.4725 - accuracy: 0.7612\n",
            "Epoch 30/30\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 2.1734 - accuracy: 0.7015\n",
            "13/13 [==============================] - 0s 27ms/step - loss: 2.5784 - accuracy: 0.6633\n",
            "\n",
            "\n",
            "Test Loss 2.5783634919386644, Test Accuracy 0.6632911562919617\n",
            "Predicted survival: 9.33%  | Actual outcome:  1\n",
            "Predicted survival: 15.06%  | Actual outcome:  1\n",
            "Predicted survival: 49.87%  | Actual outcome:  0\n",
            "Predicted survival: 7.38%  | Actual outcome:  0\n",
            "Predicted survival: 60.96%  | Actual outcome:  1\n",
            "Predicted survival: 12.49%  | Actual outcome:  1\n",
            "Predicted survival: 1.28%  | Actual outcome:  0\n",
            "Predicted survival: 1.19%  | Actual outcome:  1\n",
            "Predicted survival: 3.13%  | Actual outcome:  1\n",
            "Predicted survival: 0.90%  | Actual outcome:  1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CHDModel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wkw87MplLSTb",
        "colab_type": "code",
        "outputId": "f293a1a2-b438-405e-c248-477c8072e443",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import functools\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "#TRAIN_DATA_URL = \"heart_train.csv\"\n",
        "#TEST_DATA_URL = \"heart_test.csv\"\n",
        "\n",
        "\n",
        "\n",
        "#train_file_path = tf.keras.utils.get_file(\"heart_train.csv\",TRAIN_DATA_URL)\n",
        "#test_file_path = tf.keras.utils.get_file(\"heart_test.csv\",TEST_DATA_URL)\n",
        "\n",
        "\n",
        "\n",
        "# Make numpy values easier to read.\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "\n",
        "\n",
        "\n",
        "#!head {'heart_train.csv'}\n",
        "\n",
        "\n",
        "\n",
        "LABEL_COLUMN = 'chd'\n",
        "LABELS = [0, -1]\n",
        "\n",
        "\n",
        "\n",
        "def get_dataset(file_path, **kwargs):\n",
        "  dataset = tf.data.experimental.make_csv_dataset(\n",
        "      file_path,\n",
        "      batch_size=32, # Artificially small to make examples easier to show.\n",
        "      label_name=LABEL_COLUMN,\n",
        "      na_value=\"?\",\n",
        "      num_epochs=1,\n",
        "      ignore_errors=True, \n",
        "      **kwargs)\n",
        "  return dataset\n",
        "\n",
        "\n",
        "\n",
        "raw_train_data = get_dataset(\"heart_train.csv\")\n",
        "raw_test_data = get_dataset(\"heart_test.csv\")\n",
        "\n",
        "\n",
        "def show_batch(dataset):\n",
        "  for batch, label in dataset.take(1):\n",
        "    for key, value in batch.items():\n",
        "       print(\"{:20s}: {}\".format(key,value.numpy()))\n",
        "\n",
        "\n",
        "show_batch(raw_train_data)\n",
        "\n",
        "\n",
        "\n",
        "CSV_COLUMNS = ['row.names', 'sbp', 'tobacco', 'ldl', 'adiposity', 'famhist', 'typea', 'obesity', 'alcohol', 'age','chd']\n",
        "\n",
        "temp_dataset = get_dataset(\"heart_train.csv\", column_names=CSV_COLUMNS)\n",
        "\n",
        "show_batch(temp_dataset)\n",
        "\n",
        "\n",
        "\n",
        "SELECT_COLUMNS = ['sbp', 'tobacco', 'ldl', 'adiposity', 'famhist', 'typea', 'obesity', 'alcohol', 'age','chd']\n",
        "\n",
        "temp_dataset = get_dataset(\"heart_train.csv\", select_columns=SELECT_COLUMNS)\n",
        "\n",
        "show_batch(temp_dataset)\n",
        "\n",
        "\n",
        "\n",
        "#def pack(features, label):\n",
        "#  return tf.stack(list(features.values()), axis=-1), label\n",
        "\n",
        "\n",
        "#packed_dataset = temp_dataset.map(pack)\n",
        "\n",
        "#for features, labels in packed_dataset.take(1):\n",
        "#  print(features.numpy())\n",
        "#  print()\n",
        "#  print(labels.numpy())\n",
        "\n",
        "\n",
        "\n",
        "#show_batch(raw_train_data)\n",
        "\n",
        "example_batch, labels_batch = next(iter(temp_dataset)) \n",
        "\n",
        "\n",
        "class PackNumericFeatures(object):\n",
        "  def __init__(self, names):\n",
        "    self.names = names\n",
        "\n",
        "  def __call__(self, features, labels):\n",
        "    numeric_features = [features.pop(name) for name in self.names]\n",
        "    numeric_features = [tf.cast(feat, tf.float32) for feat in numeric_features]\n",
        "    numeric_features = tf.stack(numeric_features, axis=-1)\n",
        "    features['numeric'] = numeric_features\n",
        "\n",
        "    return features, labels\n",
        "\n",
        "\n",
        "NUMERIC_FEATURES = ['sbp', 'tobacco', 'ldl', 'adiposity', 'typea', 'obesity', 'alcohol', 'age']\n",
        "\n",
        "packed_train_data = raw_train_data.map(\n",
        "    PackNumericFeatures(NUMERIC_FEATURES))\n",
        "\n",
        "packed_test_data = raw_test_data.map(\n",
        "    PackNumericFeatures(NUMERIC_FEATURES))\n",
        "\n",
        "#show_batch(\"heart_train.csv\")\n",
        "\n",
        "example_batch, labels_batch = next(iter(packed_train_data)) \n",
        "\n",
        "import pandas as pd\n",
        "desc = pd.read_csv(\"heart_train.csv\")[NUMERIC_FEATURES].describe()\n",
        "desc\n",
        "\n",
        "\n",
        "MEAN = np.array(desc.T['mean'])\n",
        "STD = np.array(desc.T['std'])\n",
        "\n",
        "\n",
        "def normalize_numeric_data(data, mean, std):\n",
        "  # Center the data\n",
        "  return (data-mean)/std\n",
        "\n",
        "\n",
        "# See what you just created.\n",
        "normalizer = functools.partial(normalize_numeric_data, mean=MEAN, std=STD)\n",
        "\n",
        "numeric_column = tf.feature_column.numeric_column('numeric', normalizer_fn=normalizer, shape=[len(NUMERIC_FEATURES)])\n",
        "numeric_columns = [numeric_column]\n",
        "numeric_column\n",
        "\n",
        "\n",
        "example_batch['numeric']\n",
        "\n",
        "numeric_layer = tf.keras.layers.DenseFeatures(numeric_columns)\n",
        "numeric_layer(example_batch).numpy()\n",
        "\n",
        "\n",
        "CATEGORIES = {\n",
        "    'famhist' : ['Present', 'Absent']\n",
        "}\n",
        "\n",
        "categorical_columns = []\n",
        "for feature, vocab in CATEGORIES.items():\n",
        "  cat_col = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "        key=feature, vocabulary_list=vocab)\n",
        "  categorical_columns.append(tf.feature_column.indicator_column(cat_col))\n",
        "\n",
        "\n",
        "# See what you just created.\n",
        "categorical_columns\n",
        "\n",
        "categorical_layer = tf.keras.layers.DenseFeatures(categorical_columns)\n",
        "print(categorical_layer(example_batch).numpy()[0])\n",
        "\n",
        "\n",
        "preprocessing_layer = tf.keras.layers.DenseFeatures(categorical_columns+numeric_columns)\n",
        "\n",
        "print(preprocessing_layer(example_batch).numpy()[0])\n",
        "\n",
        "#Build the model\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  preprocessing_layer,\n",
        "  tf.keras.layers.Dense(1000, activation='elu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "  tf.keras.layers.Dropout(0.25),\n",
        "  tf.keras.layers.Dense(1000, activation='elu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Dense(1000, activation='elu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  #tf.keras.layers.Dense(256, activation='elu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "  #tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(0.001)),\n",
        "\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "#Train, evaluate, and predict\n",
        "\n",
        "train_data = packed_train_data.shuffle(500)\n",
        "\n",
        "#train_data = packed_train_data\n",
        "test_data = packed_test_data\n",
        "\n",
        "\n",
        "model.fit(train_data, epochs=30)\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "\n",
        "print('\\n\\nTest Loss {}, Test Accuracy {}'.format(test_loss, test_accuracy))\n",
        "\n",
        "\n",
        "\n",
        "predictions = model.predict(test_data)\n",
        "\n",
        "# Show some results\n",
        "for prediction, survived in zip(predictions[:10], list(test_data)[0][1][:10]):\n",
        "  print(\"Predicted survival: {:.2%}\".format(prediction[0]),\n",
        "        \" | Actual outcome: \",\n",
        "        (\"1\" if bool(survived) else \"0\"))\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "row.names           : [435 409 459 434 425 439 444 457 426 461 452 451 443 414 402 429 448 432\n",
            " 413 407 398 397 463 417 423 400 431 438 433 445 399 455]\n",
            "sbp                 : [120 200 214 136 176 138 166 128 142 108 136 144 120 164 134 146 142 118\n",
            " 166 116 162 142 132 134 174 126 120 138 108 134 218 124]\n",
            "tobacco             : [ 0.   19.2   0.4   0.    6.    0.06  6.    2.24  2.2   3.    1.81  4.\n",
            "  0.    8.2   6.1   1.16  0.    0.    0.8   2.38  7.    0.    0.    1.1\n",
            "  0.    8.75  0.    0.    0.    0.57 11.2   1.6 ]\n",
            "ldl                 : [ 2.46  4.43  5.98  4.    3.98  4.15  8.8   2.83  3.29  1.59  3.31  5.03\n",
            "  3.98 14.16  4.77  2.28  4.32  3.89  5.63  5.67  7.67  3.54  4.82  3.54\n",
            "  3.86  6.06  3.57  1.86  1.43  4.75  2.77  7.22]\n",
            "adiposity           : [13.39 40.6  31.72 19.06 17.2  20.66 37.89 26.48 22.7  15.23  6.74 25.78\n",
            " 13.19 36.85 26.08 34.53 25.22 15.96 36.21 29.01 34.34 16.64 33.41 20.41\n",
            " 21.73 32.72 23.22 18.35 26.26 23.07 30.79 39.68]\n",
            "famhist             : [b'Absent' b'Present' b'Absent' b'Absent' b'Present' b'Absent' b'Absent'\n",
            " b'Absent' b'Absent' b'Absent' b'Absent' b'Present' b'Present' b'Absent'\n",
            " b'Absent' b'Absent' b'Absent' b'Absent' b'Absent' b'Present' b'Present'\n",
            " b'Absent' b'Present' b'Present' b'Absent' b'Present' b'Absent' b'Present'\n",
            " b'Absent' b'Absent' b'Absent' b'Present']\n",
            "typea               : [47 55 64 40 52 49 39 48 44 40 63 57 47 52 47 50 47 65 50 54 33 58 62 58\n",
            " 42 33 58 59 42 67 38 36]\n",
            "obesity             : [22.01 32.04 28.45 21.94 21.07 22.59 28.7  23.96 23.66 20.09 19.57 27.55\n",
            " 21.89 28.5  23.82 28.71 28.92 20.18 34.72 27.26 30.77 25.97 14.7  24.54\n",
            " 23.37 27.   27.2  25.38 19.38 26.33 24.86 31.5 ]\n",
            "alcohol             : [ 0.51 36.    0.    2.06  4.11  2.49 43.2  47.42  5.66 26.64 24.94 90.\n",
            "  0.   17.02  1.03 45.    6.53  0.   28.8  15.77  0.    8.36  0.   39.91\n",
            "  0.   62.43  0.    6.51  0.    0.   90.93  0.  ]\n",
            "age                 : [18 60 58 16 61 16 52 27 42 55 24 48 16 55 49 49 34 16 60 51 62 27 46 39\n",
            " 63 55 32 17 16 37 48 51]\n",
            "row.names           : [433 404 423 421 428 398 425 446 432 460 452 414 453 438 461 442 407 431\n",
            " 397 406 435 439 403 413 441 456 401 462 463 443 408 427]\n",
            "sbp                 : [108 178 174 126 142 162 176 142 118 182 136 164 120 138 108 110 116 120\n",
            " 142 160 120 138 132 166 130 146 126 118 132 120 180 132]\n",
            "tobacco             : [ 0.    5.5   0.    0.    1.32  7.    6.    3.    0.    4.2   1.81  8.2\n",
            "  0.    0.    3.    0.    2.38  0.    0.    1.15  0.    0.06  0.    0.8\n",
            "  4.    0.64  0.    5.4   0.    0.   25.01  0.  ]\n",
            "ldl                 : [ 1.43  3.79  3.86  4.55  7.63  7.67  3.98  3.69  3.89  4.41  3.31 14.16\n",
            "  2.77  1.86  1.59  7.14  5.67  3.57  3.54 10.19  2.46  4.15  4.17  5.63\n",
            "  2.4   4.82  3.57 11.61  4.82  3.98  3.7   3.3 ]\n",
            "adiposity           : [26.26 23.92 21.73 29.18 29.98 34.34 17.2  25.1  15.96 32.1   6.74 36.85\n",
            " 13.35 18.35 15.23 28.28 29.01 23.22 16.64 39.71 13.39 20.66 36.57 36.21\n",
            " 17.42 28.02 26.01 30.79 33.41 13.19 38.11 21.61]\n",
            "famhist             : [b'Absent' b'Present' b'Absent' b'Absent' b'Present' b'Present' b'Present'\n",
            " b'Absent' b'Absent' b'Absent' b'Absent' b'Absent' b'Absent' b'Present'\n",
            " b'Absent' b'Absent' b'Present' b'Absent' b'Absent' b'Absent' b'Absent'\n",
            " b'Absent' b'Absent' b'Absent' b'Absent' b'Absent' b'Absent' b'Absent'\n",
            " b'Present' b'Present' b'Present' b'Absent']\n",
            "typea               : [42 45 42 48 57 33 52 60 65 52 63 52 67 59 40 57 54 58 58 31 47 49 57 50\n",
            " 60 60 61 64 62 47 57 42]\n",
            "obesity             : [19.38 21.26 23.37 24.94 31.16 30.77 21.07 30.08 20.18 28.61 19.57 28.5\n",
            " 23.37 25.38 20.09 29.   27.26 27.2  25.97 31.65 22.01 22.59 30.61 34.72\n",
            " 22.05 28.11 26.3  27.35 14.7  21.89 30.54 24.92]\n",
            "alcohol             : [ 0.    6.17  0.   36.   72.93  0.    4.11 38.88  0.   18.72 24.94 17.02\n",
            "  1.03  6.51 26.64  0.   15.77  0.    8.36 20.52  0.51  2.49 18.   28.8\n",
            "  0.    8.23  7.97 23.97  0.    0.    0.   32.61]\n",
            "age                 : [16 62 63 41 33 62 61 27 16 52 24 55 18 17 55 32 51 32 27 57 18 16 49 60\n",
            " 40 39 47 40 46 16 61 33]\n",
            "sbp                 : [144 120 134 132 142 136 218 132 208 166 146 142 178 124 136 176 146 138\n",
            " 132 108 136 126 216 130 120 126 170 120 132 162 130 118]\n",
            "tobacco             : [ 4.    0.    6.1   7.2   0.    1.81 11.2   0.    5.04  0.8   0.64  2.2\n",
            " 20.    1.6   0.    6.    1.16  0.06  0.    0.    2.8   0.    0.92  0.\n",
            "  0.    8.75  0.4   0.    0.    7.    1.22  0.  ]\n",
            "ldl                 : [5.03 3.98 4.77 3.65 3.54 3.31 2.77 4.82 5.19 5.63 4.82 3.29 9.78 7.22\n",
            " 4.   3.98 2.28 4.15 3.55 1.43 2.53 4.55 2.66 1.88 2.77 6.06 4.11 3.57\n",
            " 4.17 7.67 3.3  3.89]\n",
            "adiposity           : [25.78 13.19 26.08 17.16 16.64  6.74 30.79 33.41 20.71 36.21 28.02 22.7\n",
            " 33.55 39.68 19.06 17.2  34.53 20.66  8.66 26.26  9.28 29.18 19.85 12.51\n",
            " 13.35 32.72 42.06 23.22 36.57 34.34 13.65 15.96]\n",
            "famhist             : [b'Present' b'Present' b'Absent' b'Present' b'Absent' b'Absent' b'Absent'\n",
            " b'Present' b'Present' b'Absent' b'Absent' b'Absent' b'Absent' b'Present'\n",
            " b'Absent' b'Present' b'Absent' b'Absent' b'Present' b'Absent' b'Present'\n",
            " b'Absent' b'Present' b'Present' b'Absent' b'Present' b'Present' b'Absent'\n",
            " b'Absent' b'Present' b'Absent' b'Absent']\n",
            "typea               : [57 47 47 56 58 63 38 62 52 50 60 44 37 36 40 52 50 49 61 42 61 48 49 52\n",
            " 67 33 56 58 57 33 50 65]\n",
            "obesity             : [27.55 21.89 23.82 23.25 25.97 19.57 24.86 14.7  25.12 34.72 28.11 23.66\n",
            " 27.29 31.5  21.94 21.07 28.71 22.59 18.5  19.38 20.7  24.94 20.58 20.28\n",
            " 23.37 27.   33.1  27.2  30.61 30.77 21.4  20.18]\n",
            "alcohol             : [90.    0.    1.03  0.    8.36 24.94 90.93  0.   24.27 28.8   8.23  5.66\n",
            "  2.88  0.    2.06  4.11 45.    2.49  3.87  0.    4.55 36.    0.51  0.\n",
            "  1.03 62.43  2.06  0.   18.    0.    3.81  0.  ]\n",
            "age                 : [48 16 49 34 27 24 48 46 58 60 39 42 62 51 16 61 49 16 16 16 25 41 63 17\n",
            " 18 55 57 32 49 62 31 16]\n",
            "[0. 1.]\n",
            "[ 0.     1.    -0.996 -0.679 -0.272 -1.106  1.549 -1.297 -0.739 -1.573]\n",
            "Epoch 1/30\n",
            "3/3 [==============================] - 1s 304ms/step - loss: 2.6741 - accuracy: 0.5672\n",
            "Epoch 2/30\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 2.6267 - accuracy: 0.7463\n",
            "Epoch 3/30\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 2.5344 - accuracy: 0.7612\n",
            "Epoch 4/30\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 2.6888 - accuracy: 0.7313\n",
            "Epoch 5/30\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 2.4257 - accuracy: 0.8060\n",
            "Epoch 6/30\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 2.4277 - accuracy: 0.8209\n",
            "Epoch 7/30\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 2.2711 - accuracy: 0.8209\n",
            "Epoch 8/30\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 2.3706 - accuracy: 0.7910\n",
            "Epoch 9/30\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 2.3014 - accuracy: 0.7910\n",
            "Epoch 10/30\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 2.2938 - accuracy: 0.7313\n",
            "Epoch 11/30\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 2.2948 - accuracy: 0.7761\n",
            "Epoch 12/30\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 2.4673 - accuracy: 0.7761\n",
            "Epoch 13/30\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 2.2518 - accuracy: 0.7910\n",
            "Epoch 14/30\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 2.3288 - accuracy: 0.7910\n",
            "Epoch 15/30\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 2.7144 - accuracy: 0.6866\n",
            "Epoch 16/30\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 2.6181 - accuracy: 0.6866\n",
            "Epoch 17/30\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 2.3706 - accuracy: 0.7910\n",
            "Epoch 18/30\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 2.5908 - accuracy: 0.7463\n",
            "Epoch 19/30\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 2.8458 - accuracy: 0.7313\n",
            "Epoch 20/30\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 2.2206 - accuracy: 0.8358\n",
            "Epoch 21/30\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 2.5250 - accuracy: 0.7463\n",
            "Epoch 22/30\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 2.2750 - accuracy: 0.7164\n",
            "Epoch 23/30\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 2.2845 - accuracy: 0.7164\n",
            "Epoch 24/30\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 2.1226 - accuracy: 0.7761\n",
            "Epoch 25/30\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 2.3508 - accuracy: 0.8060\n",
            "Epoch 26/30\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 2.1798 - accuracy: 0.7910\n",
            "Epoch 27/30\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 2.2682 - accuracy: 0.8209\n",
            "Epoch 28/30\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 2.0829 - accuracy: 0.8358\n",
            "Epoch 29/30\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 2.1156 - accuracy: 0.8358\n",
            "Epoch 30/30\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 1.9240 - accuracy: 0.8060\n",
            "13/13 [==============================] - 1s 42ms/step - loss: 2.4038 - accuracy: 0.6962\n",
            "\n",
            "\n",
            "Test Loss 2.4037967645204983, Test Accuracy 0.6962025165557861\n",
            "Predicted survival: 6.26%  | Actual outcome:  0\n",
            "Predicted survival: 37.81%  | Actual outcome:  1\n",
            "Predicted survival: 0.24%  | Actual outcome:  1\n",
            "Predicted survival: 38.09%  | Actual outcome:  0\n",
            "Predicted survival: 7.65%  | Actual outcome:  0\n",
            "Predicted survival: 0.27%  | Actual outcome:  1\n",
            "Predicted survival: 14.57%  | Actual outcome:  1\n",
            "Predicted survival: 96.08%  | Actual outcome:  1\n",
            "Predicted survival: 0.29%  | Actual outcome:  0\n",
            "Predicted survival: 15.80%  | Actual outcome:  0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}